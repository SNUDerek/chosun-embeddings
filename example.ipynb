{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chosun News Tokenizer and Vector Space Models\n",
    "\n",
    "### corpus information\n",
    "\n",
    "~11M lines of Chosun Ilbo news articles\n",
    "\n",
    "### Google sentencepiece tokenizer model\n",
    "\n",
    "trained with vocab-size of 16,000\n",
    "\n",
    "### character, mecab-morpheme and word-piece word2vec models\n",
    "\n",
    "trained with `gensim` over tokenized corpus\n",
    "\n",
    "a `generator` object was used to load sentences from disk; function is included for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import sentencepiece as spm\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embeddings with gensim\n",
    "# filename : filepath to text file\n",
    "def create_embeddings(file_name,\n",
    "                      save_path='embeddings/my_model',\n",
    "                      do_train=True,\n",
    "                      **params):\n",
    "    \n",
    "    if do_train:\n",
    "        class SentenceGenerator(object):\n",
    "            def __init__(self, filename):\n",
    "                self.filename = filename\n",
    "\n",
    "            def __iter__(self):\n",
    "                for line in codecs.open(self.filename, 'rU', encoding='utf-8'):\n",
    "                    yield line.strip().split()\n",
    "\n",
    "        sentences = SentenceGenerator(file_name)\n",
    "\n",
    "        print(\"training\", save_path, \"model...\")\n",
    "        model = Word2Vec(sentences, **params)\n",
    "        print(\"saving\", save_path, \"model...\")\n",
    "        model.save(save_path+'.gensimmodel')\n",
    "    \n",
    "    model = Word2Vec.load(save_path+'.gensimmodel')\n",
    "    print(\"saving\", save_path, \"vocab...\")\n",
    "    # http://stackoverflow.com/questions/35596031/gensim-word2vec-find-number-of-words-in-vocabulary\n",
    "    vocab = dict([(k, v.index) for k, v in model.wv.vocab.items()])\n",
    "    with open(save_path+'.json', 'w') as f:\n",
    "        f.write(json.dumps(vocab))\n",
    "\n",
    "    return model, vocab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vocab(vocab_path='embeddings/mapping.json'):\n",
    "    with open(vocab_path, 'r') as f:\n",
    "        data = json.loads(f.read())\n",
    "    word2idx = data\n",
    "    idx2word = dict([(v, k) for k, v in data.items()])\n",
    "    return word2idx, idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output filenames\n",
    "w2v_mecabfile = 'embeddings/chosun_mecab_embeddings'\n",
    "w2v_sentpfile = 'embeddings/chosun_sentp_embeddings'\n",
    "w2v_charafile = 'embeddings/chosun_chara_embeddings' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mecab-tokenized Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "267900"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mecab_w2v_model = Word2Vec.load(w2v_mecabfile+'.gensimmodel')\n",
    "mecab_w2v_vocab, _ = load_vocab(w2v_mecabfile+'.json')\n",
    "len(mecab_w2v_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('일본', 0.6532888412475586),\n",
       " ('미국', 0.6065130233764648),\n",
       " ('독일', 0.5748053789138794),\n",
       " ('중국', 0.5691663026809692),\n",
       " ('국내', 0.5494322776794434),\n",
       " ('유럽', 0.526393711566925),\n",
       " ('우리나라', 0.508824348449707),\n",
       " ('영국', 0.5084823369979858),\n",
       " ('호주', 0.5040222406387329),\n",
       " ('브라질', 0.49898624420166016)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mecab_w2v_model.wv.most_similar('한국')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sentence-piece tokenization and word2vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(\"embeddings/chosun-16k.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁h', 'ell', 'o', '▁', 'w', 'or', 'ld', '!']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.Encode(\"hello world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁저는', '▁한국', '말', '을', '▁말할', '▁수', '▁있어요']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.Encode(\"저는 한국말을 말할 수 있어요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27112"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordp_w2v_model = Word2Vec.load(w2v_sentpfile+'.gensimmodel')\n",
    "wordp_w2v_vocab, _ = load_vocab(w2v_sentpfile+'.json')\n",
    "len(wordp_w2v_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('일본', 0.6959158182144165),\n",
       " ('미국', 0.6691223382949829),\n",
       " ('중국', 0.6461528539657593),\n",
       " ('우리나라', 0.6356861591339111),\n",
       " ('대한민국', 0.6356850862503052),\n",
       " ('국내', 0.6188637018203735),\n",
       " ('영국', 0.584417462348938),\n",
       " ('우리', 0.5596229434013367),\n",
       " ('▁한국', 0.5501009821891785),\n",
       " ('북한', 0.5448728799819946)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordp_w2v_model.wv.most_similar('한국')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7320"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chara_w2v_model = Word2Vec.load(w2v_charafile+'.gensimmodel')\n",
    "chara_w2v_vocab, _ = load_vocab(w2v_charafile+'.json')\n",
    "len(chara_w2v_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('했', 0.4814152717590332),\n",
       " ('된', 0.45396751165390015),\n",
       " ('하', 0.4360974431037903),\n",
       " ('해', 0.4352923631668091),\n",
       " ('룬', 0.4349149465560913),\n",
       " ('할', 0.43141090869903564),\n",
       " ('깬', 0.40105998516082764),\n",
       " ('쓴', 0.39839059114456177),\n",
       " ('킨', 0.3684242367744446),\n",
       " ('뗀', 0.3615623414516449)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chara_w2v_model.wv.most_similar('한')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atlas",
   "language": "python",
   "name": "atlas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
